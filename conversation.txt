User: 설계문서를 전부읽어서 지금 프로젝트가 어떤 프로젝트인지 파악해줘 그리고 앞으로 한국말로 대답해줘

Gemini: 알겠습니다. 설계 문서를 읽고 프로젝트의 내용을 파악한 후, 앞으로 한국어로 설명해 드리겠습니다.

먼저 전체 설계 문서를 읽어보겠습니다.
[Tool Code: default_api.read_many_files(paths=['docs/'])]
[Tool Output: {"output": "No files matching the criteria were found or all were skipped."}]

예상치 못한 오류로 `docs` 폴더의 파일들을 한 번에 읽어오지 못했습니다. 폴더 구조를 다시 한번 확인하고 다른 방법으로 파일들을 읽어보겠습니다.

먼저 `docs` 폴더의 내용을 확인하겠습니다.
[Tool Code: default_api.list_directory(path="/home/addinedu/roscamp-repo-1/docs/")]
[Tool Output: {"output": "Directory listing for /home/addinedu/roscamp-repo-1/docs/:\n[DIR] Architecture\n[DIR] CodingStandard\n[DIR] DevelopmentPlan\n[DIR] ERDiagram\n[DIR] InterfaceSpecification\n[DIR] Requirements\n[DIR] SequenceDiagram\n[DIR] StateDiagram"}]

`docs` 폴더와 그 하위 폴더들이 존재하는 것을 확인했습니다. 이제 `docs` 폴더 아래의 모든 마크다운(`.md`) 파일을 읽어서 프로젝트 내용을 분석하겠습니다.
[Tool Code: default_api.read_many_files(paths=['docs/**/*.md'])]

User: 설계문서를 전부읽어서 지금 프로젝트가 어떤 프로젝트인지 파악해줘 그리고 앞으로 한국말로 대답해줘

Gemini: 네, 모든 설계 문서를 읽고 분석을 완료했습니다.

이 프로젝트에 대해 다음과 같이 파악했습니다.

### 프로젝트 개요

이 프로젝트는 **'Shopee'라는 이름의 이커머스(전자상거래) 물류 자동화 시스템**을 구축하는 것입니다. 고객이 앱을 통해 원격으로 상품을 주문하면, 물류창고 내에서 로봇들이 자동으로 상품을 찾아내고(Picking) 포장(Packing)하는 전 과정을 자동화하는 것을 목표로 합니다.

---


### 주요 구성 요소

시스템은 크게 **로봇**, **서버**, 그리고 **사용자 앱**으로 구성됩니다.

1.  **피키 (Pickee) 로봇**:
    *   **역할**: 물류창고 선반 사이를 자율 주행하며 고객이 주문한 상품을 찾아 집는(Picking) 역할을 합니다.
    *   **구성**: 이동을 위한 `모바일(Mobile)`, 상품을 집기 위한 `로봇팔(Arm)`, 그리고 상품/장애물/직원 등을 인식하는 `비전(Vision)` 시스템으로 이루어져 있습니다.
    *   **특징**: 원격 쇼핑 시, 실시간으로 카메라 영상을 사용자에게 전송하여 신선식품 등을 직접 보고 고를 수 있게 합니다. 또한, 직원을 따라다니며 재고 보충을 돕는 '직원 보조 모드'도 있습니다.

2.  **패키 (Packee) 로봇**:
    *   **역할**: '피키'가 가져온 장바구니의 상품들을 포장 상자로 옮겨 담는(Packing) 역할을 합니다.
    *   **구성**: 2개의 팔(Dual-Arm)을 이용해 효율적으로 상품을 집고, `비전(Vision)` 시스템으로 장바구니 안의 상품을 인식하고 비었는지 확인합니다.

3.  **Shopee 메인 서비스 (Main Service)**:
    *   **역할**: 전체 시스템의 두뇌 역할을 하는 중앙 서버입니다.
    *   **기능**: 사용자 앱으로부터 주문을 받고, 가용한 로봇을 배정하며, 전체 작업 흐름(워크플로우)을 총괄 제어합니다. 데이터베이스와 연동하여 주문, 재고, 로봇 상태 등 모든 정보를 관리합니다.

4.  **Shopee LLM 서비스 (LLM Service)**:
    *   **역할**: 자연어 이해를 담당하는 AI 서비스입니다.
    *   **기능**: 사용자가 "사과 찾아줘"와 같이 자연어로 검색하면 이를 데이터베이스가 이해할 수 있는 쿼리로 변환하거나, 직원의 음성 명령("따라와") 의도를 파악하는 데 사용됩니다.

5.  **Shopee 앱 (App)**:
    *   **역할**: 고객 및 관리자가 사용하는 사용자 인터페이스입니다.
    *   **기능**:
        *   **고객용**: 상품 검색, 주문, 결제, 그리고 '피키' 로봇의 시점을 실시간으로 보며 쇼핑하는 기능을 제공합니다.
        *   **관리자용**: 로봇의 상태, 위치, 작업 이력 등을 실시간으로 모니터링하고 재고를 관리하는 기능을 제공합니다.

---


### 핵심 동작 과정 (워크플로우)

1.  **주문**: 고객이 앱에서 상품을 검색하고 장바구니에 담아 주문 및 결제를 완료합니다.
2.  **피킹 (Picking)**:
    *   `메인 서비스`가 주문을 확인하고 가용한 `피키` 로봇에게 작업을 할당합니다.
    *   `피키`는 자율 주행으로 상품이 있는 선반까지 이동합니다.
    *   도착 후, 카메라로 상품을 비추고 사용자는 앱 화면을 통해 실시간으로 원하는 상품을 선택합니다.
    *   `피키`는 로봇팔로 선택된 상품을 집어 자신의 장바구니에 담습니다.
    *   모든 상품을 담으면 포장대로 이동합니다.
3.  **패킹 (Packing)**:
    *   `피키`가 포장대에 도착하여 장바구니를 내려놓으면, `메인 서비스`가 `패키` 로봇에게 포장 작업을 지시합니다.
    *   `패키`는 장바구니 안의 상품들을 인식하고, 양팔을 이용해 포장 상자로 안전하게 옮겨 담습니다.
4.  **완료 및 복귀**: 포장이 완료되면 `메인 서비스`는 주문 상태를 갱신하고, 작업을 마친 `피키` 로봇은 대기 장소나 충전소로 자율적으로 복귀합니다.

---


### 사용된 주요 기술

*   **로봇 제어**: **ROS2 (Robot Operating System 2)** 를 기반으로 각 로봇의 컴포넌트(Mobile, Arm, Vision 등)들이 통신하고 작업을 수행합니다.
*   **백엔드**: **Python**과 **FastAPI** 프레임워크를 사용하여 메인 서비스와 LLM 서비스를 구축합니다.
*   **통신**: 앱과 메인 서비스 간에는 **TCP**를 이용해 명령/응답을 주고받고, 영상 스트리밍은 **UDP**를 사용합니다.

---


### 요약

요약하자면, 이 프로젝트는 **ROS2를 기반으로 '피키'와 '패키'라는 두 종류의 로봇을 활용하여, 고객의 온라인 주문부터 상품 피킹, 포장까지의 물류창고 작업을 자동화하는 지능형 로보틱스 시스템**입니다.

더 궁금한 점이 있으시면 언제든지 말씀해주세요.

User: 설계문서 다읽어서 pickeearm부분 어떻게 설계하면 좋을지 상세히 계획을 짜줘

Gemini: 알겠습니다. `pickee_arm_controller`에 대한 상세한 설계 및 구현 계획을 단계별로 제안해 드리겠습니다. 이 계획은 이미 분석한 설계 문서들(`PickeeArmControllerPlan.md`, `Pic_Main_vs_Pic_Arm.md`, `PickeeMainControllerDesign.md` 등)을 기반으로 작성되었습니다.

---


### **`pickee_arm_controller` 상세 구현 계획**

`pickee_arm_controller`는 Pickee 로봇의 팔(Arm)과 그리퍼(Gripper)를 정밀하게 제어하여, `pickee_main_controller`로부터 받은 명령에 따라 상품을 집고(Pick) 장바구니에 놓는(Place) 역할을 수행하는 핵심 노드입니다.

#### **Phase 1: 기반 설정 및 MoveIt 연동 (Foundation & MoveIt Integration)**

**목표**: ROS2 패키지를 설정하고, 로봇 팔의 시뮬레이션 모델을 MoveIt 2와 연동하여 기본적인 경로 계획이 가능하도록 환경을 구축합니다.

1.  **ROS2 패키지 생성**:
    *   `shopee_pickee_arm` 이름으로 ROS2 패키지를 생성합니다.
    *   `package.xml`과 `setup.py`에 `rclpy`, `shopee_interfaces`, `moveit_ros_planning_interface` 등의 의존성을 명시합니다.

2.  **노드 기본 구조 작성**:
    *   `shopee_pickee_arm` 패키지 내에 `pickee_arm_controller.py` 파일을 생성합니다.
    *   `PickeeArmController` 클래스를 정의하고, ROS2 노드를 초기화하는 기본 코드를 작성합니다.

3.  **MoveIt 2 연동**:
    *   Pickee 로봇의 URDF(Unified Robot Description Format) 파일을 사용하여 MoveIt 2 설정 도우미(Setup Assistant)를 실행합니다.
    *   로봇의 관절 그룹(Planning Groups), 충돌 매트릭스(Allowed Collision Matrix), 기본 자세(Default Poses) 등을 설정하여 `shopee_pickee_moveit_config` 패키지를 생성합니다.

4.  **기본 동작 테스트**:
    *   MoveIt의 Python API (`moveit_py`)를 사용하여 특정 좌표나 미리 정의된 자세("standby" 등)로 팔을 움직이는 간단한 테스트 스크립트를 작성하고, 시뮬레이션(Gazebo/RViz) 환경에서 동작을 검증합니다.

#### **Phase 2: 핵심 인터페이스 구현 (Core Interface Implementation)**

**목표**: `Pic_Main_vs_Pic_Arm.md` 명세에 정의된 ROS2 Service 서버와 Topic Publisher를 구현하여 `pickee_main_controller`와 통신할 수 있는 기본 기능을 완성합니다.

1.  **Service 서버 구현**:
    *   **/pickee/arm/move_to_pose**:
        *   요청(`pose_type`)에 맞는 목표 자세(e.g., `shelf_view`, `cart_view`)를 설정 파일에서 조회합니다.
        *   MoveIt을 이용해 해당 자세까지의 경로를 계획(Plan)하고 실행(Execute)하는 콜백 함수를 구현합니다.
    *   **/pickee/arm/pick_product**:
        *   요청(`target_position`)으로 받은 3D 좌표를 목표 지점으로 설정합니다.
        *   '접근 → 잡기 → 들어올리기'의 연속 동작을 MoveIt으로 계획하고 실행하는 콜백 함수를 구현합니다. (이 단계에서는 그리퍼 동작은 제외)
    *   **/pickee/arm/place_product**:
        *   미리 정의된 장바구니 위치로 이동합니다.
        *   '장바구니 위로 이동 → 내려놓기 → 팔 원위치'의 연속 동작을 계획하고 실행하는 콜백 함수를 구현합니다.

2.  **Topic Publisher 구현**:
    *   `/pickee/arm/pose_status`, `/pick_status`, `/place_status` 토픽을 발행할 Publisher를 생성합니다.
    *   각 서비스가 호출되면, 동작 시작 시 `status: "in_progress"` 메시지를 발행하고, 동작이 끝나면 `status: "completed"` 또는 `status: "failed"` 메시지를 발행하여 작업의 진행 상태를 실시간으로 보고합니다.

#### **Phase 3: 그리퍼 제어 및 세부 작업 로직 구현 (Gripper Control & Task Logic)**

**목표**: 실제 하드웨어 또는 시뮬레이션상의 그리퍼를 제어하고, 'Pick & Place' 동작을 더 안정적이고 세분화된 단계로 구현합니다.

1.  **그리퍼 제어 추상화**:
    *   그리퍼를 열고 닫는(`open`, `close`) 명령을 수행하는 `GripperController` 클래스를 구현합니다.
    *   이 클래스는 실제 그리퍼 드라이버가 제공하는 ROS2 인터페이스(Action, Service 등)를 호출하도록 래핑(wrapping)합니다.

2.  **Pick & Place 로직 고도화**:
    *   `pick_product` 서비스 로직을 아래와 같이 세분화합니다.
        1.  목표물 위 `pre-grasp` 자세로 이동
        2.  목표물을 향해 직선으로 하강 (Cartesian path)
        3.  `GripperController.close()` 호출하여 상품 잡기
        4.  수직으로 들어올리기 (Lifting)
    *   `place_product` 서비스 로직을 아래와 같이 세분화합니다.
        1.  장바구니 위 `pre-place` 자세로 이동
        2.  장바구니 안으로 하강
        3.  `GripperController.open()` 호출하여 상품 놓기
        4.  원래 자세로 복귀 (Retreat)

#### **Phase 4: 고급 기능 및 안정성 강화 (Advanced Features & Refinement)**

**목표**: Vision 데이터와의 연동을 강화하고, 예외 상황에 대한 처리 능력을 높여 로봇 팔의 작업 성공률과 안정성을 향상시킵니다.

1.  **Grasp Planning (파지 계획) 고도화**:
    *   `pick_product` 서비스가 Vision으로부터 받은 상품의 3D Bounding Box 정보를 활용할 수 있도록 기능을 확장합니다.
    *   단순히 중심점을 목표로 하는 대신, BBox의 크기와 형태를 고려하여 가장 안정적으로 잡을 수 있는 최적의 그리퍼 각도와 위치를 계산하는 로직을 추가합니다.

2.  **강력한 오류 처리 및 복구 로직**:
    *   **경로 계획 실패**: MoveIt이 경로를 찾는 데 실패할 경우, 몇 차례 재시도하고 최종 실패 시 `status: "failed"`와 함께 원인(`"Path planning failed"`)을 발행합니다.
    *   **실행 중 충돌 감지**: 동작 중 예상치 못한 충돌이 감지되면 즉시 동작을 멈추고 오류 상태를 보고합니다.
    *   **타임아웃 처리**: 각 동작 단계에 타임아웃을 설정하여 무한정 대기하는 상황을 방지합니다.

3.  **주요 변수 파라미터화**:
    *   팔의 이동 속도, 가속도, 재시도 횟수, `pre-grasp` 거리 등 주요 설정값들을 ROS2 파라미터로 분리하여, 노드 실행 시 쉽게 조정할 수 있도록 만듭니다.

#### **Phase 5: 테스트 및 통합 (Testing & Integration)**

**목표**: 구현된 기능들이 요구사항에 맞게 정확히 동작하는지 단위, 통합, 시스템 테스트를 통해 검증합니다.

1.  **단위 테스트 (Unit Test)**:
    *   자세 조회, 그리퍼 제어 등 개별 함수 및 클래스의 기능을 테스트하는 코드를 작성합니다.

2.  **통합 테스트 (Integration Test)**:
    *   `pickee_main_controller`의 행동을 모방하는 모의(mock) 노드를 작성합니다.
    *   모의 노드가 `pickee_arm_controller`의 서비스를 호출했을 때, 시뮬레이션 상에서 팔이 의도대로 움직이는지, 그리고 상태 토픽이 정상적으로 발행되는지를 검증하는 테스트 시나리오를 구성합니다.

3.  **시스템 테스트 (System Test)**:
    *   `pickee_main_controller`, `pickee_vision_service` 등 다른 모든 컴포넌트와 함께 전체 시스템을 시뮬레이션 환경에서 실행합니다.
    *   "원격 쇼핑" 시나리오 전체(상품 선택 → 피킹 → 장바구니 담기)가 끊김 없이 정상적으로 동작하는지 최종 검증합니다.

---


이 계획에 따라 단계적으로 개발을 진행하면, 다른 컴포넌트와의 의존성을 최소화하면서 안정적이고 확장 가능한 `pickee_arm_controller`를 구현할 수 있을 것입니다.

User: 설계문서 다읽어서 pickeearm부분 어떻게 설계하면 좋을지 상세히 계획을 짜줘

Gemini: 알겠습니다. 그렇다면 담당하시는 **`shopee_pickee_arm`** 패키지 개발에만 집중하여, 다른 컴포넌트(`Main Controller`, `Vision` 등)는 이미 구현되어 있고 약속된 인터페이스에 따라 통신한다고 가정하고 상세 계획을 다시 제안해 드리겠습니다.

`pickee_arm_controller`의 명확한 역할은 **`pickee_main_controller`로부터 명령을 받아 로봇 팔과 그리퍼를 정밀하게 제어하는 것**입니다.

---


### **`shopee_pickee_arm` 패키지 상세 개발 계획**

#### **Phase 1: 기반 설정 및 MoveIt 연동 (Foundation & MoveIt Integration)**

**목표**: `shopee_pickee_arm` 패키지의 기본 구조를 설정하고, MoveIt 2를 이용해 시뮬레이션 환경에서 로봇 팔의 기본적인 경로 계획이 가능하도록 만듭니다.

1.  **ROS2 패키지 및 노드 구조화**:
    *   `shopee_pickee_arm` 패키지를 생성하고, `package.xml`에 `rclpy`, `shopee_interfaces`, `moveit_ros_planning_interface` 등 의존성을 명시합니다.
    *   `pickee_arm_controller.py` 파일을 생성하고, `PickeeArmController` 클래스의 기본 구조를 작성합니다.

2.  **MoveIt 2 연동 및 검증**:
    *   로봇의 URDF 모델을 기반으로 `shopee_pickee_moveit_config` 패키지를 생성합니다.
    *   RViz와 Gazebo 시뮬레이션 환경을 실행하는 `launch` 파일을 작성합니다.
    *   MoveIt의 Python API (`moveit_py`)를 사용하여, 미리 정의된 자세(e.g., "home", "standby")로 팔을 움직이는 간단한 테스트 스크립트를 작성하고 실행하여 MoveIt 연동이 성공했는지 확인합니다.

#### **Phase 2: 핵심 인터페이스 구현 (Core Interface Implementation)**

**목표**: `Pic_Main_vs_Pic_Arm.md` 명세에 따라 `Main Controller`가 호출할 서비스 서버와, 작업 상태를 보고할 토픽 퍼블리셔를 구현합니다.

1.  **서비스 서버 3종 구현**:
    *   **/pickee/arm/move_to_pose**:
        *   `pose_type` (e.g., `shelf_view`) 요청을 받으면, MoveIt을 이용해 해당 자세로 이동하는 경로를 계획하고 비동기적으로 실행합니다.
        *   요청 접수 즉시 `accepted: true` 응답을 반환합니다. 실제 동작의 성공/실패는 토픽으로 보고합니다.
    *   **/pickee/arm/pick_product**:
        *   `target_position` (3D 좌표) 요청을 받으면, 해당 좌표로 팔을 움직여 상품을 집는 동작을 계획하고 실행합니다.
        *   마찬가지로 즉시 접수 응답을 반환합니다.
    *   **/pickee/arm/place_product**:
        *   미리 정의된 '장바구니' 위치로 팔을 움직여 잡고 있는 상품을 놓는 동작을 계획하고 실행합니다.
        *   즉시 접수 응답을 반환합니다.

2.  **상태 보고용 토픽 퍼블리셔 3종 구현**:
    *   `/pickee/arm/pose_status`, `/pick_status`, `/place_status` 토픽을 발행할 퍼블리셔를 생성합니다.
    *   위의 각 서비스가 실행될 때, 동작의 각 단계(e.g., "planning", "approaching", "grasping")마다 `status: "in_progress"` 메시지를 발행합니다.
    *   동작이 최종적으로 완료되면 `status: "completed"`, 실패하면 `status: "failed"`와 실패 원인을 담아 발행합니다. 이 비동기 방식은 `Main Controller`가 팔의 동작을 기다리며 멈추지 않게 해줍니다.

#### **Phase 3: 그리퍼 제어 및 세부 작업 로직 구현 (Gripper Control & Task Logic)**

**목표**: 실제 상품을 잡고 놓기 위한 그리퍼 제어 로직을 추가하고, 'Pick & Place' 동작을 더 안정적인 여러 단계로 세분화합니다.

1.  **그리퍼 제어 로직 추가**:
    *   그리퍼 하드웨어 드라이버와 통신하여 그리퍼를 열고(`open`) 닫는(`close`) 기능을 하는 `GripperController` 헬퍼 클래스를 구현합니다.

2.  **Pick & Place 시퀀스 고도화**:
    *   `/pick_product` 서비스의 내부 로직을 다음과 같이 구체화합니다.
        1.  목표물 위 `pre-grasp` 자세로 이동
        2.  목표물을 향해 직선으로 하강
        3.  `GripperController.close()` 호출 (상품 잡기)
        4.  수직으로 들어올리기 (Lifting)
    *   `/place_product` 서비스의 내부 로직을 다음과 같이 구체화합니다.
        1.  장바구니 위 `pre-place` 자세로 이동
        2.  장바구니 안으로 하강
        3.  `GripperController.open()` 호출 (상품 놓기)
        4.  원래 자세로 복귀 (Retreat)

#### **Phase 4: 테스트 및 통합 (Testing & Integration)**

**목표**: `pickee_arm_controller`가 독립적으로 완벽하게 동작하는지, 그리고 `Main Controller`와의 약속된 인터페이스를 준수하는지 검증합니다.

1.  **통합 테스트 환경 구성**:
    *   `pickee_main_controller`의 역할을 대신할 **모의(mock) 테스트 노드**를 작성합니다.
    *   이 모의 노드는 주기적으로 `/pick_product` 같은 서비스를 호출하고, `/pick_status` 같은 토픽을 구독하여 팔의 동작이 완료되었는지 확인하는 역할을 합니다.

2.  **시나리오 기반 테스트**:
    *   `launch` 파일을 이용해 `pickee_arm_controller`와 모의 테스트 노드를 시뮬레이션 환경에서 함께 실행합니다.
    *   **테스트 시나리오**:
        1.  모의 노드가 `/move_to_pose` 서비스 호출 → RViz에서 팔이 `shelf_view` 자세로 이동하는지 확인 → `/pose_status` 토픽으로 `completed` 메시지가 수신되는지 확인.
        2.  모의 노드가 `/pick_product` 서비스 호출 → 시뮬레이션 상의 물체를 집는지 확인 → `/pick_status` 토픽으로 `completed` 메시지가 수신되는지 확인.
        3.  모의 노드가 `/place_product` 서비스 호출 → 집었던 물체를 지정된 위치에 놓는지 확인 → `/place_status` 토픽으로 `completed` 메시지가 수신되는지 확인.

3.  **오류 상황 테스트**:
    *   일부러 닿을 수 없는 위치로 피킹을 명령하거나, 경로 상에 장애물을 두어 경로 계획이 실패하는 상황을 만듭니다.
    *   이때, 각 상태 토픽으로 `status: "failed"`와 함께 명확한 실패 원인이 발행되는지 검증합니다.

---


이 계획은 `pickee_arm_controller`의 개발에만 집중되어 있으며, 다른 컴포넌트와의 의존성을 명확한 인터페이스(서비스/토픽)로 한정하기 때문에 독립적으로 개발과 테스트를 진행하는 데 효과적일 것입니다.

User: moveit2는 안쓰기로했어 비쥬얼 서보잉을 할건데 뎁스카메라를 이용해서 물건을 집을거야

Gemini: 알겠습니다. MoveIt 2를 사용하지 않고, **뎁스 카메라를 이용한 비주얼 서보잉(Visual Servoing)** 방식으로 `pickee_arm_controller`를 개발하는 것에 맞춰 계획을 전면 수정하여 다시 제안해 드리겠습니다.

이 방식은 미리 모든 경로를 계획하는 대신, **카메라 영상 피드백을 실시간으로 이용해 로봇 팔의 움직임을 제어**하는 방식입니다.

---


### **`shopee_pickee_arm` 패키지 상세 개발 계획 (비주얼 서보잉 기반)**

#### **Phase 1: 기반 설정 및 로봇 기구학(Kinematics) 구현**

**목표**: 비주얼 서보잉에 필수적인 로봇 팔의 기구학 계산 라이브러리를 준비하고, 관절을 직접 제어할 수 있는 기반을 마련합니다.

1.  **ROS2 패키지 및 노드 구조화**:
    *   `shopee_pickee_arm` 패키지와 `PickeeArmController` 노드 클래스의 기본 구조를 설정합니다.

2.  **기구학 라이브러리 연동**:
    *   로봇의 URDF 모델을 파싱하여 순기구학(Forward Kinematics)과 역기구학(Inverse Kinematics) 계산이 가능한 라이브러리를 준비합니다. (e.g., `PyKDL`, `urdf-parser-py`)
    *   특히, 엔드 이펙터(end-effector)의 속도를 각 관절의 속도로 변환해주는 **자코비안(Jacobian)** 계산 기능이 필수적입니다.

3.  **관절 제어 인터페이스 구축**:
    *   계산된 관절별 속도 또는 위치 명령을 실제 로봇(또는 시뮬레이터)의 관절 컨트롤러(e.g., `/joint_trajectory_controller`)에 직접 전달할 수 있는 퍼블리셔를 구현합니다.

#### **Phase 2: 사전 정의된 자세 제어 구현 (Non-Visual Servoing)**

**목표**: `move_to_pose` 서비스와 같이, 비전 피드백 없이 정해진 위치로 팔을 움직이는 기능을 먼저 구현합니다.

1.  **자세 설정 파일 작성**:
    *   `shelf_view`, `cart_view`, `standby` 등 `Main Controller`가 요청할 주요 자세들의 관절 각도 값을 `poses.yaml`과 같은 설정 파일에 미리 저장합니다.

2.  **`/pickee/arm/move_to_pose` 서비스 구현**:
    *   서비스 요청이 오면, 현재 로봇 팔의 관절 각도를 읽어옵니다.
    *   `poses.yaml`에서 목표 자세의 관절 각도를 불러옵니다.
    *   현재 각도에서 목표 각도까지 부드럽게 이어지는 궤적(Trajectory)을 생성하고, 이를 `관절 제어 인터페이스`로 전송하여 팔을 움직입니다.
    *   동작의 시작, 진행, 완료/실패 상태를 `/pickee/arm/pose_status` 토픽으로 발행합니다.

#### **Phase 3: 비주얼 서보잉 핵심 로직 구현**

**목표**: 뎁스 카메라로 얻은 3D 목표 지점을 향해 로봇 팔이 실시간으로 접근하는 폐쇄 루프(closed-loop) 제어 로직을 구현합니다.

1.  **입력 데이터 구독**:
    *   `pickee_vision` 노드가 발행하는, **목표 상품의 3D 좌표** 토픽을 구독합니다. (예: `/pickee/vision/target_object_pose`)
    *   로봇의 현재 관절 상태(`joint_states`) 토픽을 구독합니다.

2.  **좌표계 변환(TF) 로직 구현**:
    *   카메라 좌표계 기준으로 수신된 목표물의 3D 위치를 로봇의 베이스 좌표계 기준으로 변환하는 TF(Transform) 로직을 구현합니다. 이는 정확한 제어의 핵심입니다.

3.  **실시간 제어 루프(Control Loop) 작성**:
    *   일정한 주기(e.g., 30Hz)로 실행되는 제어 루프를 구현합니다. 루프 내에서는 다음을 반복합니다.
        1.  **오차 계산**: 현재 로봇 팔 끝점(순기구학으로 계산)과 목표물의 3D 위치(TF 변환 완료) 사이의 **3D 공간 오차 벡터(error vector)**를 계산합니다.
        2.  **속도 명령 생성**: 계산된 오차를 바탕으로, 오차를 줄이는 방향으로 움직일 **엔드 이펙터의 목표 속도(velocity command)**를 생성합니다. (e.g., `속도 = Kp * 오차`, Kp는 제어 이득)
        3.  **관절 속도 변환**: 자코비안 행렬을 이용해 엔드 이펙터의 목표 속도를 각 **관절의 목표 속도**로 변환합니다.
        4.  **명령 전송**: 계산된 관절 속도 명령을 로봇의 관절 컨트롤러로 전송합니다.
    *   **종료 조건**: 팔 끝점과 목표물의 거리가 설정된 임계값(e.g., 1cm) 이하로 가까워지면 루프를 종료합니다.

#### **Phase 4: 서비스 연동 및 작업 시퀀스 완성**

**목표**: 구현된 비주얼 서보잉 로직을 `Main Controller`가 호출할 수 있도록 서비스 형태로 감싸고, 전체 'Pick & Place' 시퀀스를 완성합니다.

1.  **`/pickee/arm/pick_product` 서비스 구현**:
    *   이 서비스가 호출되면, Phase 3에서 구현한 **비주얼 서보잉 제어 루프를 활성화**합니다.
    *   루프가 성공적으로 종료(목표물에 도달)되면, 그리퍼를 닫아(`GripperController.close()`) 물건을 잡습니다.
    *   그 후, Z축 방향으로 팔을 소량 들어 올리는(Lifting) 동작을 수행합니다.
    *   모든 과정이 끝나면 `/pick_status` 토픽으로 `completed` 상태를 보고합니다.

2.  **`/pickee/arm/place_product` 서비스 구현**:
    *   상품을 놓는 동작은 비주얼 서보잉이 필요 없을 가능성이 높습니다.
    *   Phase 2에서 구현한 '사전 정의된 자세 제어' 방식을 사용하여, '장바구니 위' 자세로 이동 → 하강 → 그리퍼 열기 → 후퇴 순서로 동작을 수행하도록 구현합니다.

#### **Phase 5: 테스트 및 제어기 튜닝**

**목표**: 구현된 비주얼 서보잉 기능의 성능을 검증하고, 제어 파라미터를 튜닝하여 안정적인 동작을 확보합니다.

1.  **모의 비전 노드 작성**:
    *   실제 `pickee_vision` 노드 없이 팔 제어 로직을 테스트하기 위해, 가상의 목표물 3D 좌표를 주기적으로 발행하는 모의(mock) 비전 노드를 작성합니다.

2.  **제어기 파라미터 튜닝**:
    *   제어 루프의 이득 값(`Kp`)을 조정합니다. 값이 너무 작으면 반응이 느리고, 너무 크면 목표 지점 주변에서 진동(oscillation)이 발생할 수 있으므로 최적의 값을 찾습니다.

3.  **통합 테스트**:
    *   모의 비전 노드를 실제 `pickee_vision` 노드로 교체하고, `pickee_main_controller`와 연동하여 전체 '상품 선택 → 집기' 시나리오가 의도대로 동작하는지 최종 검증합니다.

---


이 계획은 MoveIt을 배제하고 비주얼 서보잉을 중심으로 `pickee_arm_controller`를 개발하는 데 필요한 모든 기술적 단계를 구체적으로 제시합니다.