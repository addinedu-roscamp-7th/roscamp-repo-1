import cv2
import pickle
import numpy as np

# ğŸ”¹ 1. ì €ì¥ëœ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
with open('camera_calibration.pkl', 'rb') as f:
    calib_data = pickle.load(f)

camera_matrix = calib_data['camera_matrix']
dist_coeffs = calib_data['dist_coeffs']

# ğŸ”¹ 2. ArUco ë”•ì…”ë„ˆë¦¬ ë° íŒŒë¼ë¯¸í„° ì„¤ì •
aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)
aruco_params = cv2.aruco.DetectorParameters()

# ğŸ”¹ 3. ì¹´ë©”ë¼ ì¥ì¹˜ ì—´ê¸°
cap = cv2.VideoCapture(2)  # í•„ìš”ì‹œ ì¸ë±ìŠ¤ë¥¼ 2 ë“±ìœ¼ë¡œ ë³€ê²½

# ğŸ”¹ ë§ˆì»¤ í•œ ë³€ì˜ ì‹¤ì œ ê¸¸ì´(mm ë‹¨ìœ„)
marker_length = 50  # ì˜ˆ: 3cmì§œë¦¬ ë§ˆì»¤ë¼ë©´ 30mm

print("ğŸ¥ ArUco ì¸ì‹ ì‹œì‘ ('q' í‚¤ë¡œ ì¢…ë£Œ)")

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        break

    # ğŸ”¹ 4. ì™œê³¡ ë³´ì •
    frame_undistorted = cv2.undistort(frame, camera_matrix, dist_coeffs)

    # ğŸ”¹ 5. ë§ˆì»¤ ê²€ì¶œ
    detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)
    corners, ids, rejected = detector.detectMarkers(frame_undistorted)

    if ids is not None:
        # ğŸ”¹ ë§ˆì»¤ í‘œì‹œ
        cv2.aruco.drawDetectedMarkers(frame_undistorted, corners, ids)

        # ğŸ”¹ 6. ê° ë§ˆì»¤ì˜ ìì„¸(íšŒì „Â·ì´ë™ ë²¡í„°) ê³„ì‚°
        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(
            corners, marker_length, camera_matrix, dist_coeffs
        )

        for rvec, tvec, marker_id in zip(rvecs, tvecs, ids):
            # ì¶• ê·¸ë¦¬ê¸° (x:ë¹¨ê°•, y:ì´ˆë¡, z:íŒŒë‘)
            cv2.drawFrameAxes(frame_undistorted, camera_matrix, dist_coeffs, rvec, tvec, marker_length * 0.5)

            # ì¢Œí‘œ ì¶œë ¥
            pos = tvec.flatten()
            print(f"ğŸŸ¢ ID {marker_id[0]} ìœ„ì¹˜(mm): x={pos[0]:.1f}, y={pos[1]:.1f}, z={pos[2]:.1f}")

    # ğŸ”¹ 7. í™”ë©´ í‘œì‹œ
    cv2.imshow("ArUco Marker Detection", frame_undistorted)

    # ğŸ”¹ 8. ì¢…ë£Œ í‚¤
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
